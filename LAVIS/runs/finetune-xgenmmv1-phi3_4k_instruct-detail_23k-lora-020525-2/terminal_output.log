================== Parsed Arguments ===================
model_family: xgenmm_v1
vision_encoder_path: google/siglip-so400m-patch14-384
vision_encoder_pretrained: google
lm_path: microsoft/Phi-3-mini-4k-instruct
tokenizer_path: microsoft/Phi-3-mini-4k-instruct
lora: True
cross_attn_every_n_layers: 1
num_vision_tokens: 128
pretrained: /workspace/LAVIS/base_model_weight/xgen-mm-phi3-mini-base-r-v1.5.pt
pretrained_vision_tokenizer: None
loss: supervised_finetune
run_name: finetune-xgenmmv1-phi3_4k_instruct-detail_23k-lora-020525-2
resume_from_checkpoint: None
delete_previous_checkpoint: False
no_save_optim_state: True
gradient_accumulation_steps: 8
seed: 42
learning_rate: 2e-05
lr_scheduler: cosine
warmup_steps: 2000
weight_decay: 0.0
precision: amp_bf16
gradient_checkpointing: True
num_epochs: 1
offline: False
logging_steps: 100
checkpoint_steps: 5000
data_path: data_configs/detail_23k.yaml
batch_size: 1
workers: 2
data_sampler_group_by_length: True
is_multimodal: True
mm_use_im_start_end: False
conv_template_name: phi_3
image_aspect_ratio: anyres
anyres_patch_sampling: True
anyres_grids: [(1, 2), (2, 1), (2, 2), (3, 1), (1, 3)]
dist_url: env://
dist_backend: nccl
horovod: False
no_set_device_rank: False
local_rank: 0
fsdp: False
fsdp_sharding_strategy: full
report_to_wandb: False
wandb_project: None
wandb_entity: None
save_checkpoints_to_wandb: False
dryrun: False
use_flash_attention_2: False
unfreeze_vision_encoder: False
vision_encoder_precision: fp32
cpu_offload_gradients: False
=======================================================
Initializing distributed training with 1 GPUs.
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 11.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.04s/it]
xgenmm_v1 model initialized with 3,931,031,619 trainable parameters
==========Trainable Parameters
Vision encoder: 0 trainable parameters
Vision tokenizer: 109,901,568 trainable parameters
Language model: 3,821,130,051 trainable parameters
==========Total Parameters
Vision encoder: 428,225,600 parameters
Vision tokenizer: 109,901,568 parameters
Language model: 3,821,130,051 parameters
==========
Found no checkpoints for run finetune-xgenmmv1-phi3_4k_instruct-detail_23k-lora-020525-2.
Loading checkpoint from /workspace/LAVIS/base_model_weight/xgen-mm-phi3-mini-base-r-v1.5.pt
Missing keys: []
Unexpected keys: []
Finished loading checkpoint...
Wrapping model in LoRA
['vision_tokenizer.projection', 'vision_tokenizer.layers.0.0.to_q', 'vision_tokenizer.layers.0.0.to_kv', 'vision_tokenizer.layers.0.0.to_out', 'vision_tokenizer.layers.0.1.1', 'vision_tokenizer.layers.0.1.3', 'vision_tokenizer.layers.1.0.to_q', 'vision_tokenizer.layers.1.0.to_kv', 'vision_tokenizer.layers.1.0.to_out', 'vision_tokenizer.layers.1.1.1', 'vision_tokenizer.layers.1.1.3', 'vision_tokenizer.layers.2.0.to_q', 'vision_tokenizer.layers.2.0.to_kv', 'vision_tokenizer.layers.2.0.to_out', 'vision_tokenizer.layers.2.1.1', 'vision_tokenizer.layers.2.1.3', 'vision_tokenizer.layers.3.0.to_q', 'vision_tokenizer.layers.3.0.to_kv', 'vision_tokenizer.layers.3.0.to_out', 'vision_tokenizer.layers.3.1.1', 'vision_tokenizer.layers.3.1.3', 'vision_tokenizer.layers.4.0.to_q', 'vision_tokenizer.layers.4.0.to_kv', 'vision_tokenizer.layers.4.0.to_out', 'vision_tokenizer.layers.4.1.1', 'vision_tokenizer.layers.4.1.3', 'vision_tokenizer.layers.5.0.to_q', 'vision_tokenizer.layers.5.0.to_kv', 'vision_tokenizer.layers.5.0.to_out', 'vision_tokenizer.layers.5.1.1', 'vision_tokenizer.layers.5.1.3', 'lang_model.model.layers.0.self_attn.o_proj', 'lang_model.model.layers.0.self_attn.qkv_proj', 'lang_model.model.layers.0.mlp.gate_up_proj', 'lang_model.model.layers.0.mlp.down_proj', 'lang_model.model.layers.1.self_attn.o_proj', 'lang_model.model.layers.1.self_attn.qkv_proj', 'lang_model.model.layers.1.mlp.gate_up_proj', 'lang_model.model.layers.1.mlp.down_proj', 'lang_model.model.layers.2.self_attn.o_proj', 'lang_model.model.layers.2.self_attn.qkv_proj', 'lang_model.model.layers.2.mlp.gate_up_proj', 'lang_model.model.layers.2.mlp.down_proj', 'lang_model.model.layers.3.self_attn.o_proj', 'lang_model.model.layers.3.self_attn.qkv_proj', 'lang_model.model.layers.3.mlp.gate_up_proj', 'lang_model.model.layers.3.mlp.down_proj', 'lang_model.model.layers.4.self_attn.o_proj', 'lang_model.model.layers.4.self_attn.qkv_proj', 'lang_model.model.layers.4.mlp.gate_up_proj', 'lang_model.model.layers.4.mlp.down_proj', 'lang_model.model.layers.5.self_attn.o_proj', 'lang_model.model.layers.5.self_attn.qkv_proj', 'lang_model.model.layers.5.mlp.gate_up_proj', 'lang_model.model.layers.5.mlp.down_proj', 'lang_model.model.layers.6.self_attn.o_proj', 'lang_model.model.layers.6.self_attn.qkv_proj', 'lang_model.model.layers.6.mlp.gate_up_proj', 'lang_model.model.layers.6.mlp.down_proj', 'lang_model.model.layers.7.self_attn.o_proj', 'lang_model.model.layers.7.self_attn.qkv_proj', 'lang_model.model.layers.7.mlp.gate_up_proj', 'lang_model.model.layers.7.mlp.down_proj', 'lang_model.model.layers.8.self_attn.o_proj', 'lang_model.model.layers.8.self_attn.qkv_proj', 'lang_model.model.layers.8.mlp.gate_up_proj', 'lang_model.model.layers.8.mlp.down_proj', 'lang_model.model.layers.9.self_attn.o_proj', 'lang_model.model.layers.9.self_attn.qkv_proj', 'lang_model.model.layers.9.mlp.gate_up_proj', 'lang_model.model.layers.9.mlp.down_proj', 'lang_model.model.layers.10.self_attn.o_proj', 'lang_model.model.layers.10.self_attn.qkv_proj', 'lang_model.model.layers.10.mlp.gate_up_proj', 'lang_model.model.layers.10.mlp.down_proj', 'lang_model.model.layers.11.self_attn.o_proj', 'lang_model.model.layers.11.self_attn.qkv_proj', 'lang_model.model.layers.11.mlp.gate_up_proj', 'lang_model.model.layers.11.mlp.down_proj', 'lang_model.model.layers.12.self_attn.o_proj', 'lang_model.model.layers.12.self_attn.qkv_proj', 'lang_model.model.layers.12.mlp.gate_up_proj', 'lang_model.model.layers.12.mlp.down_proj', 'lang_model.model.layers.13.self_attn.o_proj', 'lang_model.model.layers.13.self_attn.qkv_proj', 'lang_model.model.layers.13.mlp.gate_up_proj', 'lang_model.model.layers.13.mlp.down_proj', 'lang_model.model.layers.14.self_attn.o_proj', 'lang_model.model.layers.14.self_attn.qkv_proj', 'lang_model.model.layers.14.mlp.gate_up_proj', 'lang_model.model.layers.14.mlp.down_proj', 'lang_model.model.layers.15.self_attn.o_proj', 'lang_model.model.layers.15.self_attn.qkv_proj', 'lang_model.model.layers.15.mlp.gate_up_proj', 'lang_model.model.layers.15.mlp.down_proj', 'lang_model.model.layers.16.self_attn.o_proj', 'lang_model.model.layers.16.self_attn.qkv_proj', 'lang_model.model.layers.16.mlp.gate_up_proj', 'lang_model.model.layers.16.mlp.down_proj', 'lang_model.model.layers.17.self_attn.o_proj', 'lang_model.model.layers.17.self_attn.qkv_proj', 'lang_model.model.layers.17.mlp.gate_up_proj', 'lang_model.model.layers.17.mlp.down_proj', 'lang_model.model.layers.18.self_attn.o_proj', 'lang_model.model.layers.18.self_attn.qkv_proj', 'lang_model.model.layers.18.mlp.gate_up_proj', 'lang_model.model.layers.18.mlp.down_proj', 'lang_model.model.layers.19.self_attn.o_proj', 'lang_model.model.layers.19.self_attn.qkv_proj', 'lang_model.model.layers.19.mlp.gate_up_proj', 'lang_model.model.layers.19.mlp.down_proj', 'lang_model.model.layers.20.self_attn.o_proj', 'lang_model.model.layers.20.self_attn.qkv_proj', 'lang_model.model.layers.20.mlp.gate_up_proj', 'lang_model.model.layers.20.mlp.down_proj', 'lang_model.model.layers.21.self_attn.o_proj', 'lang_model.model.layers.21.self_attn.qkv_proj', 'lang_model.model.layers.21.mlp.gate_up_proj', 'lang_model.model.layers.21.mlp.down_proj', 'lang_model.model.layers.22.self_attn.o_proj', 'lang_model.model.layers.22.self_attn.qkv_proj', 'lang_model.model.layers.22.mlp.gate_up_proj', 'lang_model.model.layers.22.mlp.down_proj', 'lang_model.model.layers.23.self_attn.o_proj', 'lang_model.model.layers.23.self_attn.qkv_proj', 'lang_model.model.layers.23.mlp.gate_up_proj', 'lang_model.model.layers.23.mlp.down_proj', 'lang_model.model.layers.24.self_attn.o_proj', 'lang_model.model.layers.24.self_attn.qkv_proj', 'lang_model.model.layers.24.mlp.gate_up_proj', 'lang_model.model.layers.24.mlp.down_proj', 'lang_model.model.layers.25.self_attn.o_proj', 'lang_model.model.layers.25.self_attn.qkv_proj', 'lang_model.model.layers.25.mlp.gate_up_proj', 'lang_model.model.layers.25.mlp.down_proj', 'lang_model.model.layers.26.self_attn.o_proj', 'lang_model.model.layers.26.self_attn.qkv_proj', 'lang_model.model.layers.26.mlp.gate_up_proj', 'lang_model.model.layers.26.mlp.down_proj', 'lang_model.model.layers.27.self_attn.o_proj', 'lang_model.model.layers.27.self_attn.qkv_proj', 'lang_model.model.layers.27.mlp.gate_up_proj', 'lang_model.model.layers.27.mlp.down_proj', 'lang_model.model.layers.28.self_attn.o_proj', 'lang_model.model.layers.28.self_attn.qkv_proj', 'lang_model.model.layers.28.mlp.gate_up_proj', 'lang_model.model.layers.28.mlp.down_proj', 'lang_model.model.layers.29.self_attn.o_proj', 'lang_model.model.layers.29.self_attn.qkv_proj', 'lang_model.model.layers.29.mlp.gate_up_proj', 'lang_model.model.layers.29.mlp.down_proj', 'lang_model.model.layers.30.self_attn.o_proj', 'lang_model.model.layers.30.self_attn.qkv_proj', 'lang_model.model.layers.30.mlp.gate_up_proj', 'lang_model.model.layers.30.mlp.down_proj', 'lang_model.model.layers.31.self_attn.o_proj', 'lang_model.model.layers.31.self_attn.qkv_proj', 'lang_model.model.layers.31.mlp.gate_up_proj', 'lang_model.model.layers.31.mlp.down_proj', 'lang_model.lm_head.additional_fc']
trainable params: 27,310,128 || all params: 4,386,567,347 || trainable%: 0.6226
================== Data mixture config ===================
{'data_path': {'/workspace/detail_23k.json': 2000}}
==========================================================
Total training steps: 250
DistributedDataParallel(
  (module): PeftModel(
    (base_model): LoraModel(
      (model): XGenMMPerceiver(
        (vision_encoder): SiglipVisionTransformer(
          (embeddings): SiglipVisionEmbeddings(
            (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)
            (position_embedding): Embedding(729, 1152)
          )
          (encoder): SiglipEncoder(
            (layers): ModuleList(
              (0-26): 27 x SiglipEncoderLayer(
                (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
                (self_attn): SiglipAttention(
                  (k_proj): Linear(in_features=1152, out_features=1152, bias=True)
                  (v_proj): Linear(in_features=1152, out_features=1152, bias=True)
                  (q_proj): Linear(in_features=1152, out_features=1152, bias=True)
                  (out_proj): Linear(in_features=1152, out_features=1152, bias=True)
                )
                (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
                (mlp): SiglipMLP(
                  (activation_fn): PytorchGELUTanh()
                  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
                  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
                )
              )
            )
          )
          (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (head): SiglipMultiheadAttentionPoolingHead(
            (attention): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1152, out_features=1152, bias=True)
            )
            (layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
            (mlp): SiglipMLP(
              (activation_fn): PytorchGELUTanh()
              (fc1): Linear(in_features=1152, out_features=4304, bias=True)
              (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            )
          )
        )
        (vision_tokenizer): CheckpointWrapper(
          (_checkpoint_wrapped_module): PerceiverResampler(
            (projection): lora.Linear(
              (base_layer): Linear(in_features=1152, out_features=3072, bias=True)
              (lora_dropout): ModuleDict(
                (default): Dropout(p=0.05, inplace=False)
              )
              (lora_A): ModuleDict(
                (default): Linear(in_features=1152, out_features=16, bias=False)
              )
              (lora_B): ModuleDict(
                (default): Linear(in_features=16, out_features=3072, bias=False)
              )
              (lora_embedding_A): ParameterDict()
              (lora_embedding_B): ParameterDict()
              (lora_magnitude_vector): ModuleDict()
            )
            (layers): ModuleList(
              (0-5): 6 x ModuleList(
                (0): PerceiverAttention(
                  (norm_media): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)
                  (norm_latents): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)
                  (to_q): lora.Linear(
                    (base_layer): Linear(in_features=1152, out_features=1536, bias=False)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.05, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1152, out_features=16, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=16, out_features=1536, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                    (lora_magnitude_vector): ModuleDict()
                  )
                  (to_kv): lora.Linear(
                    (base_layer): Linear(in_features=1152, out_features=3072, bias=False)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.05, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1152, out_features=16, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=16, out_features=3072, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                    (lora_magnitude_vector): ModuleDict()
                  )
                  (to_out): lora.Linear(
                    (base_layer): Linear(in_features=1536, out_features=1152, bias=False)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.05, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1536, out_features=16, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=16, out_features=1152, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                    (lora_magnitude_vector): ModuleDict()
                  )
                )
                (1): Sequential(
                  (0): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)
                  (1): lora.Linear(
                    (base_layer): Linear(in_features=1152, out_features=4608, bias=False)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.05, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1152, out_features=16, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=16, out_features=4608, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                    (lora_magnitude_vector): ModuleDict()
                  )
                  (2): GELU(approximate='none')
                  (3): lora.Linear(
                    (base_layer): Linear(in_features=4608, out_features=1152, bias=False)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.05, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=4608, out_features=16, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=16, out_features=1152, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                    (lora_magnitude_vector): ModuleDict()
                  )
                )
              )
            )
            (norm): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)
          )
        )
        (lang_model): Phi3ForCausalLM(
          (model): Phi3Model(
            (embed_tokens): DecoupledEmbedding(
              num_original_embeddings=32012, num_additional_embeddings=3, embedding_dim=3072, partially_freeze=True
              (additional_embedding): Embedding(3, 3072)
            )
            (embed_dropout): Dropout(p=0.0, inplace=False)
            (layers): ModuleList(
              (0-31): 32 x CheckpointWrapper(
                (_checkpoint_wrapped_module): Phi3DecoderLayer(
                  (self_attn): Phi3Attention(
                    (o_proj): lora.Linear(
                      (base_layer): Linear(in_features=3072, out_features=3072, bias=False)
                      (lora_dropout): ModuleDict(
                        (default): Dropout(p=0.05, inplace=False)
                      )
                      (lora_A): ModuleDict(
                        (default): Linear(in_features=3072, out_features=16, bias=False)
                      )
                      (lora_B): ModuleDict(
                        (default): Linear(in_features=16, out_features=3072, bias=False)
                      )
                      (lora_embedding_A): ParameterDict()
                      (lora_embedding_B): ParameterDict()
                      (lora_magnitude_vector): ModuleDict()
                    )
                    (qkv_proj): lora.Linear(
                      (base_layer): Linear(in_features=3072, out_features=9216, bias=False)
                      (lora_dropout): ModuleDict(
                        (default): Dropout(p=0.05, inplace=False)
                      )
                      (lora_A): ModuleDict(
                        (default): Linear(in_features=3072, out_features=16, bias=False)
                      )
                      (lora_B): ModuleDict(
                        (default): Linear(in_features=16, out_features=9216, bias=False)
                      )
                      (lora_embedding_A): ParameterDict()
                      (lora_embedding_B): ParameterDict()
                      (lora_magnitude_vector): ModuleDict()
                    )
                    (rotary_emb): Phi3RotaryEmbedding()
                  )
                  (mlp): Phi3MLP(
                    (gate_up_proj): lora.Linear(
                      (base_layer): Linear(in_features=3072, out_features=16384, bias=False)
                      (lora_dropout): ModuleDict(
                        (default): Dropout(p=0.05, inplace=False)
                      )
                      (lora_A): ModuleDict(
                        (default): Linear(in_features=3072, out_features=16, bias=False)
                      )
                      (lora_B): ModuleDict(
                        (default): Linear(in_features=16, out_features=16384, bias=False)
                      )
                      (lora_embedding_A): ParameterDict()
                      (lora_embedding_B): ParameterDict()
                      (lora_magnitude_vector): ModuleDict()
                    )
                    (down_proj): lora.Linear(
                      (base_layer): Linear(in_features=8192, out_features=3072, bias=False)
                      (lora_dropout): ModuleDict(
                        (default): Dropout(p=0.05, inplace=False)
                      )
                      (lora_A): ModuleDict(
                        (default): Linear(in_features=8192, out_features=16, bias=False)
                      )
                      (lora_B): ModuleDict(
                        (default): Linear(in_features=16, out_features=3072, bias=False)
                      )
                      (lora_embedding_A): ParameterDict()
                      (lora_embedding_B): ParameterDict()
                      (lora_magnitude_vector): ModuleDict()
                    )
                    (activation_fn): SiLU()
                  )
                  (input_layernorm): Phi3RMSNorm()
                  (resid_attn_dropout): Dropout(p=0.0, inplace=False)
                  (resid_mlp_dropout): Dropout(p=0.0, inplace=False)
                  (post_attention_layernorm): Phi3RMSNorm()
                )
              )
            )
            (norm): Phi3RMSNorm()
          )
          (lm_head): DecoupledLinear(
            in_features=3072, out_features=32012, additional_out_features=3, bias=True, partially_freeze=True
            (additional_fc): lora.Linear(
              (base_layer): Linear(in_features=3072, out_features=3, bias=True)
              (lora_dropout): ModuleDict(
                (default): Dropout(p=0.05, inplace=False)
              )
              (lora_A): ModuleDict(
                (default): Linear(in_features=3072, out_features=16, bias=False)
              )
              (lora_B): ModuleDict(
                (default): Linear(in_features=16, out_features=3, bias=False)
              )
              (lora_embedding_A): ParameterDict()
              (lora_embedding_B): ParameterDict()
              (lora_magnitude_vector): ModuleDict()
            )
          )
        )
      )
    )
  )
)
Start running training on rank 0.
  0%|          | 0/2000 [00:00<?, ?it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 220]) attention_mask.shape=torch.Size([1, 220]) labels.shape=torch.Size([1, 220])

You are not running the flash-attention implementation, expect numerical differences.
loss=tensor(1.8092, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 1/2000 [00:01<59:06,  1.77s/it]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 189]) attention_mask.shape=torch.Size([1, 189]) labels.shape=torch.Size([1, 189])

loss=tensor(1.8671, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 2/2000 [00:02<39:26,  1.18s/it]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 194]) attention_mask.shape=torch.Size([1, 194]) labels.shape=torch.Size([1, 194])

loss=tensor(1.6807, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 3/2000 [00:03<33:07,  1.00it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 188]) attention_mask.shape=torch.Size([1, 188]) labels.shape=torch.Size([1, 188])

loss=tensor(2.3690, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 4/2000 [00:03<26:37,  1.25it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[424, 640]] input_ids.shape=torch.Size([1, 183]) attention_mask.shape=torch.Size([1, 183]) labels.shape=torch.Size([1, 183])

loss=tensor(2.0267, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 5/2000 [00:04<27:13,  1.22it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 186]) attention_mask.shape=torch.Size([1, 186]) labels.shape=torch.Size([1, 186])

loss=tensor(2.0117, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 6/2000 [00:05<26:51,  1.24it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[333, 500]] input_ids.shape=torch.Size([1, 155]) attention_mask.shape=torch.Size([1, 155]) labels.shape=torch.Size([1, 155])

loss=tensor(2.0277, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 7/2000 [00:05<23:15,  1.43it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[425, 640]] input_ids.shape=torch.Size([1, 145]) attention_mask.shape=torch.Size([1, 145]) labels.shape=torch.Size([1, 145])

loss=tensor(2.1498, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 8/2000 [00:06<24:07,  1.38it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 259]) attention_mask.shape=torch.Size([1, 259]) labels.shape=torch.Size([1, 259])

loss=tensor(1.7259, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 9/2000 [00:07<24:52,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 204]) attention_mask.shape=torch.Size([1, 204]) labels.shape=torch.Size([1, 204])

loss=tensor(1.7993, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  0%|          | 10/2000 [00:08<24:48,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 361]] input_ids.shape=torch.Size([1, 197]) attention_mask.shape=torch.Size([1, 197]) labels.shape=torch.Size([1, 197])

loss=tensor(1.6843, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 11/2000 [00:08<22:15,  1.49it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 203]) attention_mask.shape=torch.Size([1, 203]) labels.shape=torch.Size([1, 203])

loss=tensor(1.7126, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 12/2000 [00:09<23:01,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 201]) attention_mask.shape=torch.Size([1, 201]) labels.shape=torch.Size([1, 201])

loss=tensor(1.6452, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 13/2000 [00:10<23:24,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 180]) attention_mask.shape=torch.Size([1, 180]) labels.shape=torch.Size([1, 180])

loss=tensor(1.7105, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 14/2000 [00:10<23:43,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 424]] input_ids.shape=torch.Size([1, 159]) attention_mask.shape=torch.Size([1, 159]) labels.shape=torch.Size([1, 159])

loss=tensor(2.1389, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 15/2000 [00:11<24:43,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 437]] input_ids.shape=torch.Size([1, 159]) attention_mask.shape=torch.Size([1, 159]) labels.shape=torch.Size([1, 159])

loss=tensor(1.8405, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 16/2000 [00:12<24:37,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 229]) attention_mask.shape=torch.Size([1, 229]) labels.shape=torch.Size([1, 229])

loss=tensor(1.9892, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 17/2000 [00:13<24:49,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 205]) attention_mask.shape=torch.Size([1, 205]) labels.shape=torch.Size([1, 205])

loss=tensor(1.8804, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 18/2000 [00:14<24:48,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 333]] input_ids.shape=torch.Size([1, 192]) attention_mask.shape=torch.Size([1, 192]) labels.shape=torch.Size([1, 192])

loss=tensor(1.6871, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 19/2000 [00:14<22:13,  1.49it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 425]] input_ids.shape=torch.Size([1, 200]) attention_mask.shape=torch.Size([1, 200]) labels.shape=torch.Size([1, 200])

loss=tensor(1.8277, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 20/2000 [00:15<22:54,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 424]] input_ids.shape=torch.Size([1, 205]) attention_mask.shape=torch.Size([1, 205]) labels.shape=torch.Size([1, 205])

loss=tensor(1.8284, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 21/2000 [00:16<23:28,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 166]) attention_mask.shape=torch.Size([1, 166]) labels.shape=torch.Size([1, 166])

loss=tensor(1.7731, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 22/2000 [00:16<23:39,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 165]) attention_mask.shape=torch.Size([1, 165]) labels.shape=torch.Size([1, 165])

loss=tensor(1.5102, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 23/2000 [00:17<21:19,  1.55it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 164]) attention_mask.shape=torch.Size([1, 164]) labels.shape=torch.Size([1, 164])

loss=tensor(1.6789, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|          | 24/2000 [00:17<22:10,  1.49it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 229]) attention_mask.shape=torch.Size([1, 229]) labels.shape=torch.Size([1, 229])

loss=tensor(1.7805, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|▏         | 25/2000 [00:18<23:02,  1.43it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 478]] input_ids.shape=torch.Size([1, 230]) attention_mask.shape=torch.Size([1, 230]) labels.shape=torch.Size([1, 230])

loss=tensor(1.9067, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|▏         | 26/2000 [00:19<23:36,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 199]) attention_mask.shape=torch.Size([1, 199]) labels.shape=torch.Size([1, 199])

loss=tensor(2.1614, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|▏         | 27/2000 [00:20<23:52,  1.38it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 212]) attention_mask.shape=torch.Size([1, 212]) labels.shape=torch.Size([1, 212])

loss=tensor(1.7009, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|▏         | 28/2000 [00:21<24:04,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[609, 640]] input_ids.shape=torch.Size([1, 170]) attention_mask.shape=torch.Size([1, 170]) labels.shape=torch.Size([1, 170])

loss=tensor(2.1998, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  1%|▏         | 29/2000 [00:21<24:46,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 171]) attention_mask.shape=torch.Size([1, 171]) labels.shape=torch.Size([1, 171])

loss=tensor(1.9475, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 30/2000 [00:22<22:07,  1.48it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[514, 640]] input_ids.shape=torch.Size([1, 163]) attention_mask.shape=torch.Size([1, 163]) labels.shape=torch.Size([1, 163])

loss=tensor(2.0294, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 31/2000 [00:23<22:45,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 148]) attention_mask.shape=torch.Size([1, 148]) labels.shape=torch.Size([1, 148])

loss=tensor(2.2666, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 32/2000 [00:23<23:07,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 197]) attention_mask.shape=torch.Size([1, 197]) labels.shape=torch.Size([1, 197])

loss=tensor(1.9525, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 33/2000 [00:24<21:05,  1.55it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[375, 500]] input_ids.shape=torch.Size([1, 193]) attention_mask.shape=torch.Size([1, 193]) labels.shape=torch.Size([1, 193])

loss=tensor(1.9140, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 34/2000 [00:24<19:33,  1.68it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 192]) attention_mask.shape=torch.Size([1, 192]) labels.shape=torch.Size([1, 192])

loss=tensor(2.1605, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 35/2000 [00:25<21:01,  1.56it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 186]) attention_mask.shape=torch.Size([1, 186]) labels.shape=torch.Size([1, 186])

loss=tensor(1.9709, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 36/2000 [00:26<22:01,  1.49it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 188]) attention_mask.shape=torch.Size([1, 188]) labels.shape=torch.Size([1, 188])

loss=tensor(2.3173, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 37/2000 [00:26<22:44,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 190]) attention_mask.shape=torch.Size([1, 190]) labels.shape=torch.Size([1, 190])

loss=tensor(1.6561, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 38/2000 [00:27<23:14,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 178]) attention_mask.shape=torch.Size([1, 178]) labels.shape=torch.Size([1, 178])

loss=tensor(2.0816, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 39/2000 [00:28<23:32,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 170]) attention_mask.shape=torch.Size([1, 170]) labels.shape=torch.Size([1, 170])

loss=tensor(1.8773, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 40/2000 [00:29<23:46,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 225]) attention_mask.shape=torch.Size([1, 225]) labels.shape=torch.Size([1, 225])

loss=tensor(1.7882, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 41/2000 [00:29<23:59,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[428, 640]] input_ids.shape=torch.Size([1, 227]) attention_mask.shape=torch.Size([1, 227]) labels.shape=torch.Size([1, 227])

loss=tensor(1.9590, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 42/2000 [00:30<24:17,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 205]) attention_mask.shape=torch.Size([1, 205]) labels.shape=torch.Size([1, 205])

loss=tensor(1.8136, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 43/2000 [00:31<24:23,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[457, 640]] input_ids.shape=torch.Size([1, 197]) attention_mask.shape=torch.Size([1, 197]) labels.shape=torch.Size([1, 197])

loss=tensor(1.8933, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 44/2000 [00:32<25:03,  1.30it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 187]) attention_mask.shape=torch.Size([1, 187]) labels.shape=torch.Size([1, 187])

loss=tensor(2.0576, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 45/2000 [00:33<24:53,  1.31it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[500, 397]] input_ids.shape=torch.Size([1, 183]) attention_mask.shape=torch.Size([1, 183]) labels.shape=torch.Size([1, 183])

loss=tensor(2.0772, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 46/2000 [00:33<24:45,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 509]] input_ids.shape=torch.Size([1, 171]) attention_mask.shape=torch.Size([1, 171]) labels.shape=torch.Size([1, 171])

loss=tensor(1.9525, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 47/2000 [00:34<24:37,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 425]] input_ids.shape=torch.Size([1, 163]) attention_mask.shape=torch.Size([1, 163]) labels.shape=torch.Size([1, 163])

loss=tensor(2.0557, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 48/2000 [00:35<24:32,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 209]) attention_mask.shape=torch.Size([1, 209]) labels.shape=torch.Size([1, 209])

loss=tensor(1.9193, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▏         | 49/2000 [00:36<24:27,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 428]] input_ids.shape=torch.Size([1, 217]) attention_mask.shape=torch.Size([1, 217]) labels.shape=torch.Size([1, 217])

loss=tensor(2.1845, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  2%|▎         | 50/2000 [00:36<24:27,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 425]] input_ids.shape=torch.Size([1, 208]) attention_mask.shape=torch.Size([1, 208]) labels.shape=torch.Size([1, 208])

loss=tensor(1.8230, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 51/2000 [00:37<24:28,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 428]] input_ids.shape=torch.Size([1, 170]) attention_mask.shape=torch.Size([1, 170]) labels.shape=torch.Size([1, 170])

loss=tensor(2.4126, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 52/2000 [00:38<24:21,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 177]) attention_mask.shape=torch.Size([1, 177]) labels.shape=torch.Size([1, 177])

loss=tensor(1.9853, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 53/2000 [00:38<21:46,  1.49it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[500, 409]] input_ids.shape=torch.Size([1, 179]) attention_mask.shape=torch.Size([1, 179]) labels.shape=torch.Size([1, 179])

loss=tensor(2.0186, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 54/2000 [00:39<22:32,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 129]) attention_mask.shape=torch.Size([1, 129]) labels.shape=torch.Size([1, 129])

loss=tensor(2.1246, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 55/2000 [00:40<22:21,  1.45it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 424]] input_ids.shape=torch.Size([1, 131]) attention_mask.shape=torch.Size([1, 131]) labels.shape=torch.Size([1, 131])

loss=tensor(2.0738, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 56/2000 [00:40<22:47,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 191]) attention_mask.shape=torch.Size([1, 191]) labels.shape=torch.Size([1, 191])

loss=tensor(2.2489, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 57/2000 [00:41<23:17,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[528, 640]] input_ids.shape=torch.Size([1, 209]) attention_mask.shape=torch.Size([1, 209]) labels.shape=torch.Size([1, 209])

loss=tensor(1.7875, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 58/2000 [00:42<23:34,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[427, 640]] input_ids.shape=torch.Size([1, 213]) attention_mask.shape=torch.Size([1, 213]) labels.shape=torch.Size([1, 213])

loss=tensor(1.7806, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 59/2000 [00:43<23:54,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 431]] input_ids.shape=torch.Size([1, 183]) attention_mask.shape=torch.Size([1, 183]) labels.shape=torch.Size([1, 183])

loss=tensor(1.8169, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 60/2000 [00:44<24:49,  1.30it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 176]) attention_mask.shape=torch.Size([1, 176]) labels.shape=torch.Size([1, 176])

loss=tensor(2.2710, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 61/2000 [00:44<24:35,  1.31it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[375, 500]] input_ids.shape=torch.Size([1, 177]) attention_mask.shape=torch.Size([1, 177]) labels.shape=torch.Size([1, 177])

loss=tensor(2.2157, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 62/2000 [00:45<21:56,  1.47it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 456]] input_ids.shape=torch.Size([1, 148]) attention_mask.shape=torch.Size([1, 148]) labels.shape=torch.Size([1, 148])

loss=tensor(1.8376, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 63/2000 [00:46<22:26,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 147]) attention_mask.shape=torch.Size([1, 147]) labels.shape=torch.Size([1, 147])

loss=tensor(1.9130, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 64/2000 [00:46<20:41,  1.56it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 389]] input_ids.shape=torch.Size([1, 263]) attention_mask.shape=torch.Size([1, 263]) labels.shape=torch.Size([1, 263])

loss=tensor(1.7589, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 65/2000 [00:47<22:18,  1.45it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 209]) attention_mask.shape=torch.Size([1, 209]) labels.shape=torch.Size([1, 209])

loss=tensor(1.6790, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 66/2000 [00:48<22:50,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 478]] input_ids.shape=torch.Size([1, 189]) attention_mask.shape=torch.Size([1, 189]) labels.shape=torch.Size([1, 189])

loss=tensor(2.2646, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 67/2000 [00:48<23:16,  1.38it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[479, 640]] input_ids.shape=torch.Size([1, 175]) attention_mask.shape=torch.Size([1, 175]) labels.shape=torch.Size([1, 175])

loss=tensor(1.7464, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 68/2000 [00:49<23:30,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 188]) attention_mask.shape=torch.Size([1, 188]) labels.shape=torch.Size([1, 188])

loss=tensor(1.7533, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  3%|▎         | 69/2000 [00:50<23:41,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 640]] input_ids.shape=torch.Size([1, 166]) attention_mask.shape=torch.Size([1, 166]) labels.shape=torch.Size([1, 166])

loss=tensor(1.8658, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▎         | 70/2000 [00:51<23:44,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 377]] input_ids.shape=torch.Size([1, 143]) attention_mask.shape=torch.Size([1, 143]) labels.shape=torch.Size([1, 143])

loss=tensor(2.0591, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▎         | 71/2000 [00:51<21:13,  1.51it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 141]) attention_mask.shape=torch.Size([1, 141]) labels.shape=torch.Size([1, 141])

loss=tensor(1.8636, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▎         | 72/2000 [00:52<21:56,  1.46it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 220]) attention_mask.shape=torch.Size([1, 220]) labels.shape=torch.Size([1, 220])

loss=tensor(2.3106, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▎         | 73/2000 [00:53<22:39,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 215]) attention_mask.shape=torch.Size([1, 215]) labels.shape=torch.Size([1, 215])

loss=tensor(2.1808, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▎         | 74/2000 [00:53<23:49,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 189]) attention_mask.shape=torch.Size([1, 189]) labels.shape=torch.Size([1, 189])

loss=tensor(2.2178, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 75/2000 [00:54<23:56,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 193]) attention_mask.shape=torch.Size([1, 193]) labels.shape=torch.Size([1, 193])

loss=tensor(1.8193, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 76/2000 [00:55<21:27,  1.49it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 340]] input_ids.shape=torch.Size([1, 195]) attention_mask.shape=torch.Size([1, 195]) labels.shape=torch.Size([1, 195])

loss=tensor(1.7449, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 77/2000 [00:55<19:50,  1.62it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[427, 640]] input_ids.shape=torch.Size([1, 172]) attention_mask.shape=torch.Size([1, 172]) labels.shape=torch.Size([1, 172])

loss=tensor(1.9700, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 78/2000 [00:56<21:01,  1.52it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 425]] input_ids.shape=torch.Size([1, 158]) attention_mask.shape=torch.Size([1, 158]) labels.shape=torch.Size([1, 158])

loss=tensor(1.7917, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 79/2000 [00:57<21:48,  1.47it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 332]] input_ids.shape=torch.Size([1, 152]) attention_mask.shape=torch.Size([1, 152]) labels.shape=torch.Size([1, 152])

loss=tensor(1.9818, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 80/2000 [00:57<19:56,  1.60it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 202]) attention_mask.shape=torch.Size([1, 202]) labels.shape=torch.Size([1, 202])

loss=tensor(2.1250, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 81/2000 [00:58<21:10,  1.51it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 193]) attention_mask.shape=torch.Size([1, 193]) labels.shape=torch.Size([1, 193])

loss=tensor(1.8738, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 82/2000 [00:59<21:59,  1.45it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 177]) attention_mask.shape=torch.Size([1, 177]) labels.shape=torch.Size([1, 177])

loss=tensor(1.7577, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 83/2000 [00:59<22:30,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 449]] input_ids.shape=torch.Size([1, 194]) attention_mask.shape=torch.Size([1, 194]) labels.shape=torch.Size([1, 194])

loss=tensor(1.4927, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 84/2000 [01:00<22:54,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 211]] input_ids.shape=torch.Size([1, 169]) attention_mask.shape=torch.Size([1, 169]) labels.shape=torch.Size([1, 169])

loss=tensor(2.2008, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 85/2000 [01:01<20:39,  1.54it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 169]) attention_mask.shape=torch.Size([1, 169]) labels.shape=torch.Size([1, 169])

loss=tensor(1.8204, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 86/2000 [01:01<21:29,  1.48it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[478, 640]] input_ids.shape=torch.Size([1, 168]) attention_mask.shape=torch.Size([1, 168]) labels.shape=torch.Size([1, 168])

loss=tensor(1.7223, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 87/2000 [01:02<22:08,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 481]] input_ids.shape=torch.Size([1, 136]) attention_mask.shape=torch.Size([1, 136]) labels.shape=torch.Size([1, 136])

loss=tensor(2.2773, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 88/2000 [01:03<22:27,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 394]] input_ids.shape=torch.Size([1, 217]) attention_mask.shape=torch.Size([1, 217]) labels.shape=torch.Size([1, 217])

loss=tensor(1.7757, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 89/2000 [01:04<22:52,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[365, 640]] input_ids.shape=torch.Size([1, 204]) attention_mask.shape=torch.Size([1, 204]) labels.shape=torch.Size([1, 204])

loss=tensor(2.1620, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  4%|▍         | 90/2000 [01:04<20:48,  1.53it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 428]] input_ids.shape=torch.Size([1, 196]) attention_mask.shape=torch.Size([1, 196]) labels.shape=torch.Size([1, 196])

loss=tensor(2.1920, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▍         | 91/2000 [01:05<21:40,  1.47it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 193]) attention_mask.shape=torch.Size([1, 193]) labels.shape=torch.Size([1, 193])

loss=tensor(1.9190, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▍         | 92/2000 [01:06<22:15,  1.43it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 180]) attention_mask.shape=torch.Size([1, 180]) labels.shape=torch.Size([1, 180])

loss=tensor(2.1710, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▍         | 93/2000 [01:06<22:40,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 191]) attention_mask.shape=torch.Size([1, 191]) labels.shape=torch.Size([1, 191])

loss=tensor(1.8943, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▍         | 94/2000 [01:07<23:02,  1.38it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 170]) attention_mask.shape=torch.Size([1, 170]) labels.shape=torch.Size([1, 170])

loss=tensor(1.9902, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▍         | 95/2000 [01:08<23:13,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 149]) attention_mask.shape=torch.Size([1, 149]) labels.shape=torch.Size([1, 149])

loss=tensor(2.3997, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▍         | 96/2000 [01:09<23:20,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 248]) attention_mask.shape=torch.Size([1, 248]) labels.shape=torch.Size([1, 248])

loss=tensor(2.0737, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▍         | 97/2000 [01:09<23:41,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 209]) attention_mask.shape=torch.Size([1, 209]) labels.shape=torch.Size([1, 209])

loss=tensor(1.9530, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▍         | 98/2000 [01:10<23:42,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 223]) attention_mask.shape=torch.Size([1, 223]) labels.shape=torch.Size([1, 223])

loss=tensor(1.7298, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▍         | 99/2000 [01:11<23:52,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 434]] input_ids.shape=torch.Size([1, 204]) attention_mask.shape=torch.Size([1, 204]) labels.shape=torch.Size([1, 204])

loss=tensor(1.9338, device='cuda:0', grad_fn=<_DDPSinkBackward>)
Step 100/2000 of epoch 1/1 complete. Losses: train_loss: 1.934
  5%|▌         | 100/2000 [01:12<23:53,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 180]) attention_mask.shape=torch.Size([1, 180]) labels.shape=torch.Size([1, 180])

loss=tensor(1.5665, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▌         | 101/2000 [01:12<23:49,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 360]] input_ids.shape=torch.Size([1, 183]) attention_mask.shape=torch.Size([1, 183]) labels.shape=torch.Size([1, 183])

loss=tensor(1.8449, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▌         | 102/2000 [01:13<22:15,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 169]) attention_mask.shape=torch.Size([1, 169]) labels.shape=torch.Size([1, 169])

loss=tensor(2.0003, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▌         | 103/2000 [01:14<22:33,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 510]] input_ids.shape=torch.Size([1, 144]) attention_mask.shape=torch.Size([1, 144]) labels.shape=torch.Size([1, 144])

loss=tensor(2.0305, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▌         | 104/2000 [01:14<22:45,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 220]) attention_mask.shape=torch.Size([1, 220]) labels.shape=torch.Size([1, 220])

loss=tensor(2.2234, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▌         | 105/2000 [01:15<23:07,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 182]) attention_mask.shape=torch.Size([1, 182]) labels.shape=torch.Size([1, 182])

loss=tensor(1.9742, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▌         | 106/2000 [01:16<20:49,  1.52it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 356]] input_ids.shape=torch.Size([1, 183]) attention_mask.shape=torch.Size([1, 183]) labels.shape=torch.Size([1, 183])

loss=tensor(1.8155, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▌         | 107/2000 [01:16<19:13,  1.64it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 181]) attention_mask.shape=torch.Size([1, 181]) labels.shape=torch.Size([1, 181])

loss=tensor(2.3543, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▌         | 108/2000 [01:17<20:33,  1.53it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 176]) attention_mask.shape=torch.Size([1, 176]) labels.shape=torch.Size([1, 176])

loss=tensor(1.7094, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  5%|▌         | 109/2000 [01:18<21:25,  1.47it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 180]) attention_mask.shape=torch.Size([1, 180]) labels.shape=torch.Size([1, 180])

loss=tensor(2.0875, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 110/2000 [01:18<22:02,  1.43it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 478]] input_ids.shape=torch.Size([1, 156]) attention_mask.shape=torch.Size([1, 156]) labels.shape=torch.Size([1, 156])

loss=tensor(2.0624, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 111/2000 [01:19<22:22,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[453, 604]] input_ids.shape=torch.Size([1, 145]) attention_mask.shape=torch.Size([1, 145]) labels.shape=torch.Size([1, 145])

loss=tensor(2.3453, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 112/2000 [01:20<22:33,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 233]) attention_mask.shape=torch.Size([1, 233]) labels.shape=torch.Size([1, 233])

loss=tensor(2.0227, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 113/2000 [01:21<22:58,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 408]] input_ids.shape=torch.Size([1, 213]) attention_mask.shape=torch.Size([1, 213]) labels.shape=torch.Size([1, 213])

loss=tensor(1.7643, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 114/2000 [01:21<23:14,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 213]) attention_mask.shape=torch.Size([1, 213]) labels.shape=torch.Size([1, 213])

loss=tensor(2.1077, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 115/2000 [01:22<23:25,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 183]) attention_mask.shape=torch.Size([1, 183]) labels.shape=torch.Size([1, 183])

loss=tensor(2.0958, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 116/2000 [01:23<23:28,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 189]) attention_mask.shape=torch.Size([1, 189]) labels.shape=torch.Size([1, 189])

loss=tensor(2.0815, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 117/2000 [01:24<24:20,  1.29it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 458]] input_ids.shape=torch.Size([1, 194]) attention_mask.shape=torch.Size([1, 194]) labels.shape=torch.Size([1, 194])

loss=tensor(2.1851, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 118/2000 [01:24<24:01,  1.31it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 333]] input_ids.shape=torch.Size([1, 190]) attention_mask.shape=torch.Size([1, 190]) labels.shape=torch.Size([1, 190])

loss=tensor(2.0831, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 119/2000 [01:25<21:27,  1.46it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 331]] input_ids.shape=torch.Size([1, 144]) attention_mask.shape=torch.Size([1, 144]) labels.shape=torch.Size([1, 144])

loss=tensor(2.5372, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 120/2000 [01:25<19:31,  1.61it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[333, 500]] input_ids.shape=torch.Size([1, 233]) attention_mask.shape=torch.Size([1, 233]) labels.shape=torch.Size([1, 233])

loss=tensor(2.2005, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 121/2000 [01:26<18:24,  1.70it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 214]) attention_mask.shape=torch.Size([1, 214]) labels.shape=torch.Size([1, 214])

loss=tensor(1.9949, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 122/2000 [01:27<19:59,  1.57it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 196]) attention_mask.shape=torch.Size([1, 196]) labels.shape=torch.Size([1, 196])

loss=tensor(2.1456, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 123/2000 [01:27<20:59,  1.49it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 214]) attention_mask.shape=torch.Size([1, 214]) labels.shape=torch.Size([1, 214])

loss=tensor(2.0817, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▌         | 124/2000 [01:28<21:46,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 428]] input_ids.shape=torch.Size([1, 195]) attention_mask.shape=torch.Size([1, 195]) labels.shape=torch.Size([1, 195])

loss=tensor(1.8661, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▋         | 125/2000 [01:29<22:16,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 423]] input_ids.shape=torch.Size([1, 179]) attention_mask.shape=torch.Size([1, 179]) labels.shape=torch.Size([1, 179])

loss=tensor(2.1350, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▋         | 126/2000 [01:30<22:37,  1.38it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 457]] input_ids.shape=torch.Size([1, 184]) attention_mask.shape=torch.Size([1, 184]) labels.shape=torch.Size([1, 184])

loss=tensor(1.8180, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▋         | 127/2000 [01:30<22:51,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 428]] input_ids.shape=torch.Size([1, 165]) attention_mask.shape=torch.Size([1, 165]) labels.shape=torch.Size([1, 165])

loss=tensor(2.0760, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▋         | 128/2000 [01:31<23:00,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 479]] input_ids.shape=torch.Size([1, 223]) attention_mask.shape=torch.Size([1, 223]) labels.shape=torch.Size([1, 223])

loss=tensor(1.9758, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▋         | 129/2000 [01:32<23:16,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 379]] input_ids.shape=torch.Size([1, 219]) attention_mask.shape=torch.Size([1, 219]) labels.shape=torch.Size([1, 219])

loss=tensor(1.8115, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  6%|▋         | 130/2000 [01:32<21:01,  1.48it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 311]] input_ids.shape=torch.Size([1, 194]) attention_mask.shape=torch.Size([1, 194]) labels.shape=torch.Size([1, 194])

loss=tensor(1.8587, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 131/2000 [01:33<20:04,  1.55it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[612, 612]] input_ids.shape=torch.Size([1, 191]) attention_mask.shape=torch.Size([1, 191]) labels.shape=torch.Size([1, 191])

loss=tensor(2.0080, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 132/2000 [01:34<21:06,  1.47it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 184]) attention_mask.shape=torch.Size([1, 184]) labels.shape=torch.Size([1, 184])

loss=tensor(1.9831, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 133/2000 [01:34<19:23,  1.60it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 306]] input_ids.shape=torch.Size([1, 184]) attention_mask.shape=torch.Size([1, 184]) labels.shape=torch.Size([1, 184])

loss=tensor(2.0439, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 134/2000 [01:35<18:09,  1.71it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 183]) attention_mask.shape=torch.Size([1, 183]) labels.shape=torch.Size([1, 183])

loss=tensor(1.7409, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 135/2000 [01:36<19:43,  1.58it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 369]] input_ids.shape=torch.Size([1, 175]) attention_mask.shape=torch.Size([1, 175]) labels.shape=torch.Size([1, 175])

loss=tensor(2.0424, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 136/2000 [01:36<18:23,  1.69it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 222]) attention_mask.shape=torch.Size([1, 222]) labels.shape=torch.Size([1, 222])

loss=tensor(2.0980, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 137/2000 [01:37<19:56,  1.56it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 537]] input_ids.shape=torch.Size([1, 204]) attention_mask.shape=torch.Size([1, 204]) labels.shape=torch.Size([1, 204])

loss=tensor(2.0416, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 138/2000 [01:38<20:56,  1.48it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 201]) attention_mask.shape=torch.Size([1, 201]) labels.shape=torch.Size([1, 201])

loss=tensor(1.7103, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 139/2000 [01:38<21:34,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[500, 425]] input_ids.shape=torch.Size([1, 184]) attention_mask.shape=torch.Size([1, 184]) labels.shape=torch.Size([1, 184])

loss=tensor(2.1257, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 140/2000 [01:39<22:07,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 188]) attention_mask.shape=torch.Size([1, 188]) labels.shape=torch.Size([1, 188])

loss=tensor(1.8033, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 141/2000 [01:40<22:29,  1.38it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 224]] input_ids.shape=torch.Size([1, 190]) attention_mask.shape=torch.Size([1, 190]) labels.shape=torch.Size([1, 190])

loss=tensor(1.5969, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 142/2000 [01:40<20:20,  1.52it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[426, 640]] input_ids.shape=torch.Size([1, 188]) attention_mask.shape=torch.Size([1, 188]) labels.shape=torch.Size([1, 188])

loss=tensor(1.7589, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 143/2000 [01:41<21:12,  1.46it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 143]) attention_mask.shape=torch.Size([1, 143]) labels.shape=torch.Size([1, 143])

loss=tensor(1.9460, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 144/2000 [01:42<21:42,  1.43it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 573]] input_ids.shape=torch.Size([1, 218]) attention_mask.shape=torch.Size([1, 218]) labels.shape=torch.Size([1, 218])

loss=tensor(1.9819, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 145/2000 [01:43<22:14,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 385]] input_ids.shape=torch.Size([1, 228]) attention_mask.shape=torch.Size([1, 228]) labels.shape=torch.Size([1, 228])

loss=tensor(2.0051, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 146/2000 [01:43<22:57,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 201]) attention_mask.shape=torch.Size([1, 201]) labels.shape=torch.Size([1, 201])

loss=tensor(1.9347, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 147/2000 [01:44<22:57,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 192]) attention_mask.shape=torch.Size([1, 192]) labels.shape=torch.Size([1, 192])

loss=tensor(1.7734, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 148/2000 [01:45<23:03,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 190]) attention_mask.shape=torch.Size([1, 190]) labels.shape=torch.Size([1, 190])

loss=tensor(1.9494, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  7%|▋         | 149/2000 [01:46<23:05,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[427, 640]] input_ids.shape=torch.Size([1, 178]) attention_mask.shape=torch.Size([1, 178]) labels.shape=torch.Size([1, 178])

loss=tensor(2.4085, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 150/2000 [01:46<23:04,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 164]) attention_mask.shape=torch.Size([1, 164]) labels.shape=torch.Size([1, 164])

loss=tensor(1.8838, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 151/2000 [01:47<22:59,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 156]) attention_mask.shape=torch.Size([1, 156]) labels.shape=torch.Size([1, 156])

loss=tensor(2.0840, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 152/2000 [01:48<23:01,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 202]) attention_mask.shape=torch.Size([1, 202]) labels.shape=torch.Size([1, 202])

loss=tensor(1.6705, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 153/2000 [01:48<20:46,  1.48it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 195]) attention_mask.shape=torch.Size([1, 195]) labels.shape=torch.Size([1, 195])

loss=tensor(1.6638, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 154/2000 [01:49<21:28,  1.43it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 189]) attention_mask.shape=torch.Size([1, 189]) labels.shape=torch.Size([1, 189])

loss=tensor(1.9868, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 155/2000 [01:50<22:01,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 420]] input_ids.shape=torch.Size([1, 202]) attention_mask.shape=torch.Size([1, 202]) labels.shape=torch.Size([1, 202])

loss=tensor(1.8759, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 156/2000 [01:51<22:21,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 428]] input_ids.shape=torch.Size([1, 190]) attention_mask.shape=torch.Size([1, 190]) labels.shape=torch.Size([1, 190])

loss=tensor(2.1064, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 157/2000 [01:51<22:34,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 189]) attention_mask.shape=torch.Size([1, 189]) labels.shape=torch.Size([1, 189])

loss=tensor(2.0064, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 158/2000 [01:52<22:45,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 166]) attention_mask.shape=torch.Size([1, 166]) labels.shape=torch.Size([1, 166])

loss=tensor(1.6808, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 159/2000 [01:53<22:44,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 526]] input_ids.shape=torch.Size([1, 174]) attention_mask.shape=torch.Size([1, 174]) labels.shape=torch.Size([1, 174])

loss=tensor(2.3308, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 160/2000 [01:54<22:49,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 202]) attention_mask.shape=torch.Size([1, 202]) labels.shape=torch.Size([1, 202])

loss=tensor(1.6245, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 161/2000 [01:54<23:34,  1.30it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[375, 500]] input_ids.shape=torch.Size([1, 192]) attention_mask.shape=torch.Size([1, 192]) labels.shape=torch.Size([1, 192])

loss=tensor(1.7371, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 162/2000 [01:55<21:02,  1.46it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 333]] input_ids.shape=torch.Size([1, 198]) attention_mask.shape=torch.Size([1, 198]) labels.shape=torch.Size([1, 198])

loss=tensor(1.7879, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 163/2000 [01:55<19:19,  1.58it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 198]) attention_mask.shape=torch.Size([1, 198]) labels.shape=torch.Size([1, 198])

loss=tensor(2.0773, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 164/2000 [01:56<20:22,  1.50it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 478]] input_ids.shape=torch.Size([1, 196]) attention_mask.shape=torch.Size([1, 196]) labels.shape=torch.Size([1, 196])

loss=tensor(1.8144, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 165/2000 [01:57<21:07,  1.45it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 176]) attention_mask.shape=torch.Size([1, 176]) labels.shape=torch.Size([1, 176])

loss=tensor(1.6942, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 166/2000 [01:58<21:39,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 175]) attention_mask.shape=torch.Size([1, 175]) labels.shape=torch.Size([1, 175])

loss=tensor(2.1003, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 167/2000 [01:58<22:01,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 640]] input_ids.shape=torch.Size([1, 166]) attention_mask.shape=torch.Size([1, 166]) labels.shape=torch.Size([1, 166])

loss=tensor(2.0147, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 168/2000 [01:59<22:13,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 199]) attention_mask.shape=torch.Size([1, 199]) labels.shape=torch.Size([1, 199])

loss=tensor(1.9841, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 169/2000 [02:00<22:26,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 192]) attention_mask.shape=torch.Size([1, 192]) labels.shape=torch.Size([1, 192])

loss=tensor(1.6887, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  8%|▊         | 170/2000 [02:01<22:34,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 185]) attention_mask.shape=torch.Size([1, 185]) labels.shape=torch.Size([1, 185])

loss=tensor(2.2726, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▊         | 171/2000 [02:01<22:36,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 190]) attention_mask.shape=torch.Size([1, 190]) labels.shape=torch.Size([1, 190])

loss=tensor(1.8910, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▊         | 172/2000 [02:02<22:42,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 198]) attention_mask.shape=torch.Size([1, 198]) labels.shape=torch.Size([1, 198])

loss=tensor(1.9859, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▊         | 173/2000 [02:03<22:45,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 188]) attention_mask.shape=torch.Size([1, 188]) labels.shape=torch.Size([1, 188])

loss=tensor(2.2311, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▊         | 174/2000 [02:04<22:49,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 164]) attention_mask.shape=torch.Size([1, 164]) labels.shape=torch.Size([1, 164])

loss=tensor(1.9020, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 175/2000 [02:04<21:00,  1.45it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 172]) attention_mask.shape=torch.Size([1, 172]) labels.shape=torch.Size([1, 172])

loss=tensor(1.9934, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 176/2000 [02:05<21:32,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 228]) attention_mask.shape=torch.Size([1, 228]) labels.shape=torch.Size([1, 228])

loss=tensor(1.9748, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 177/2000 [02:06<22:01,  1.38it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 458]] input_ids.shape=torch.Size([1, 196]) attention_mask.shape=torch.Size([1, 196]) labels.shape=torch.Size([1, 196])

loss=tensor(2.2671, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 178/2000 [02:07<22:13,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[426, 640]] input_ids.shape=torch.Size([1, 187]) attention_mask.shape=torch.Size([1, 187]) labels.shape=torch.Size([1, 187])

loss=tensor(1.8761, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 179/2000 [02:07<22:30,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 183]) attention_mask.shape=torch.Size([1, 183]) labels.shape=torch.Size([1, 183])

loss=tensor(1.8274, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 180/2000 [02:08<22:39,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 192]) attention_mask.shape=torch.Size([1, 192]) labels.shape=torch.Size([1, 192])

loss=tensor(2.0983, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 181/2000 [02:09<22:43,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 176]) attention_mask.shape=torch.Size([1, 176]) labels.shape=torch.Size([1, 176])

loss=tensor(2.0151, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 182/2000 [02:10<22:42,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 170]) attention_mask.shape=torch.Size([1, 170]) labels.shape=torch.Size([1, 170])

loss=tensor(1.8714, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 183/2000 [02:10<22:38,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 161]) attention_mask.shape=torch.Size([1, 161]) labels.shape=torch.Size([1, 161])

loss=tensor(1.8566, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 184/2000 [02:11<22:31,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 522]] input_ids.shape=torch.Size([1, 240]) attention_mask.shape=torch.Size([1, 240]) labels.shape=torch.Size([1, 240])

loss=tensor(1.7578, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 185/2000 [02:12<22:46,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 333]] input_ids.shape=torch.Size([1, 231]) attention_mask.shape=torch.Size([1, 231]) labels.shape=torch.Size([1, 231])

loss=tensor(1.7450, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 186/2000 [02:12<20:36,  1.47it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 200]) attention_mask.shape=torch.Size([1, 200]) labels.shape=torch.Size([1, 200])

loss=tensor(1.6834, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 187/2000 [02:13<21:13,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 186]) attention_mask.shape=torch.Size([1, 186]) labels.shape=torch.Size([1, 186])

loss=tensor(1.9761, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 188/2000 [02:14<21:40,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 179]) attention_mask.shape=torch.Size([1, 179]) labels.shape=torch.Size([1, 179])

loss=tensor(1.8190, device='cuda:0', grad_fn=<_DDPSinkBackward>)
  9%|▉         | 189/2000 [02:15<21:59,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 184]) attention_mask.shape=torch.Size([1, 184]) labels.shape=torch.Size([1, 184])

loss=tensor(1.8564, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 190/2000 [02:15<22:50,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 169]) attention_mask.shape=torch.Size([1, 169]) labels.shape=torch.Size([1, 169])

loss=tensor(1.8523, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 191/2000 [02:16<22:38,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 152]) attention_mask.shape=torch.Size([1, 152]) labels.shape=torch.Size([1, 152])

loss=tensor(2.1726, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 192/2000 [02:17<22:32,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 204]) attention_mask.shape=torch.Size([1, 204]) labels.shape=torch.Size([1, 204])

loss=tensor(1.9264, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 193/2000 [02:18<22:34,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 208]) attention_mask.shape=torch.Size([1, 208]) labels.shape=torch.Size([1, 208])

loss=tensor(1.8204, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 194/2000 [02:18<22:38,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 186]) attention_mask.shape=torch.Size([1, 186]) labels.shape=torch.Size([1, 186])

loss=tensor(1.8114, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 195/2000 [02:19<22:38,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[536, 640]] input_ids.shape=torch.Size([1, 189]) attention_mask.shape=torch.Size([1, 189]) labels.shape=torch.Size([1, 189])

loss=tensor(1.7637, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 196/2000 [02:20<22:40,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 175]) attention_mask.shape=torch.Size([1, 175]) labels.shape=torch.Size([1, 175])

loss=tensor(2.1549, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 197/2000 [02:21<22:38,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 183]) attention_mask.shape=torch.Size([1, 183]) labels.shape=torch.Size([1, 183])

loss=tensor(1.6532, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 198/2000 [02:21<22:42,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 160]) attention_mask.shape=torch.Size([1, 160]) labels.shape=torch.Size([1, 160])

loss=tensor(2.2186, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|▉         | 199/2000 [02:22<22:36,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 360]] input_ids.shape=torch.Size([1, 142]) attention_mask.shape=torch.Size([1, 142]) labels.shape=torch.Size([1, 142])

loss=tensor(2.0676, device='cuda:0', grad_fn=<_DDPSinkBackward>)
Step 200/2000 of epoch 1/1 complete. Losses: train_loss: 2.068
 10%|█         | 200/2000 [02:23<20:15,  1.48it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 479]] input_ids.shape=torch.Size([1, 232]) attention_mask.shape=torch.Size([1, 232]) labels.shape=torch.Size([1, 232])

loss=tensor(1.9520, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 201/2000 [02:23<21:08,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 444]] input_ids.shape=torch.Size([1, 216]) attention_mask.shape=torch.Size([1, 216]) labels.shape=torch.Size([1, 216])

loss=tensor(1.8030, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 202/2000 [02:24<21:39,  1.38it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 395]] input_ids.shape=torch.Size([1, 192]) attention_mask.shape=torch.Size([1, 192]) labels.shape=torch.Size([1, 192])

loss=tensor(2.3317, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 203/2000 [02:25<21:56,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 512]] input_ids.shape=torch.Size([1, 200]) attention_mask.shape=torch.Size([1, 200]) labels.shape=torch.Size([1, 200])

loss=tensor(1.9483, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 204/2000 [02:26<23:02,  1.30it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[375, 500]] input_ids.shape=torch.Size([1, 205]) attention_mask.shape=torch.Size([1, 205]) labels.shape=torch.Size([1, 205])

loss=tensor(2.0128, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 205/2000 [02:26<20:42,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[426, 640]] input_ids.shape=torch.Size([1, 177]) attention_mask.shape=torch.Size([1, 177]) labels.shape=torch.Size([1, 177])

loss=tensor(1.8762, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 206/2000 [02:27<21:09,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 333]] input_ids.shape=torch.Size([1, 173]) attention_mask.shape=torch.Size([1, 173]) labels.shape=torch.Size([1, 173])

loss=tensor(2.1758, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 207/2000 [02:28<19:13,  1.55it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[427, 640]] input_ids.shape=torch.Size([1, 147]) attention_mask.shape=torch.Size([1, 147]) labels.shape=torch.Size([1, 147])

loss=tensor(1.9474, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 208/2000 [02:28<20:15,  1.47it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 214]) attention_mask.shape=torch.Size([1, 214]) labels.shape=torch.Size([1, 214])

loss=tensor(1.9055, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 209/2000 [02:29<21:08,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 203]) attention_mask.shape=torch.Size([1, 203]) labels.shape=torch.Size([1, 203])

loss=tensor(1.7327, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 10%|█         | 210/2000 [02:30<21:41,  1.38it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 192]) attention_mask.shape=torch.Size([1, 192]) labels.shape=torch.Size([1, 192])

loss=tensor(2.0738, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 211/2000 [02:31<21:59,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[427, 640]] input_ids.shape=torch.Size([1, 186]) attention_mask.shape=torch.Size([1, 186]) labels.shape=torch.Size([1, 186])

loss=tensor(1.9751, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 212/2000 [02:31<22:08,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 596]] input_ids.shape=torch.Size([1, 171]) attention_mask.shape=torch.Size([1, 171]) labels.shape=torch.Size([1, 171])

loss=tensor(2.1101, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 213/2000 [02:32<22:13,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 169]) attention_mask.shape=torch.Size([1, 169]) labels.shape=torch.Size([1, 169])

loss=tensor(2.0771, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 214/2000 [02:33<22:08,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 402]] input_ids.shape=torch.Size([1, 156]) attention_mask.shape=torch.Size([1, 156]) labels.shape=torch.Size([1, 156])

loss=tensor(2.0591, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 215/2000 [02:34<22:06,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 540]] input_ids.shape=torch.Size([1, 134]) attention_mask.shape=torch.Size([1, 134]) labels.shape=torch.Size([1, 134])

loss=tensor(2.3335, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 216/2000 [02:34<22:01,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 198]) attention_mask.shape=torch.Size([1, 198]) labels.shape=torch.Size([1, 198])

loss=tensor(1.9344, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 217/2000 [02:35<22:07,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 212]) attention_mask.shape=torch.Size([1, 212]) labels.shape=torch.Size([1, 212])

loss=tensor(2.0239, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 218/2000 [02:36<22:21,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 195]) attention_mask.shape=torch.Size([1, 195]) labels.shape=torch.Size([1, 195])

loss=tensor(2.0709, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 219/2000 [02:36<20:09,  1.47it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 190]) attention_mask.shape=torch.Size([1, 190]) labels.shape=torch.Size([1, 190])

loss=tensor(2.0305, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 220/2000 [02:37<20:49,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 208]) attention_mask.shape=torch.Size([1, 208]) labels.shape=torch.Size([1, 208])

loss=tensor(2.0062, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 221/2000 [02:38<21:20,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 168]) attention_mask.shape=torch.Size([1, 168]) labels.shape=torch.Size([1, 168])

loss=tensor(1.6950, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 222/2000 [02:39<21:33,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 333]] input_ids.shape=torch.Size([1, 160]) attention_mask.shape=torch.Size([1, 160]) labels.shape=torch.Size([1, 160])

loss=tensor(1.9289, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 223/2000 [02:39<19:24,  1.53it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 160]) attention_mask.shape=torch.Size([1, 160]) labels.shape=torch.Size([1, 160])

loss=tensor(1.9269, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█         | 224/2000 [02:40<20:17,  1.46it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 239]) attention_mask.shape=torch.Size([1, 239]) labels.shape=torch.Size([1, 239])

loss=tensor(2.1623, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█▏        | 225/2000 [02:41<21:07,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[375, 500]] input_ids.shape=torch.Size([1, 202]) attention_mask.shape=torch.Size([1, 202]) labels.shape=torch.Size([1, 202])

loss=tensor(1.8107, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█▏        | 226/2000 [02:41<19:16,  1.53it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 199]) attention_mask.shape=torch.Size([1, 199]) labels.shape=torch.Size([1, 199])

loss=tensor(1.5608, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█▏        | 227/2000 [02:42<20:11,  1.46it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 623]] input_ids.shape=torch.Size([1, 191]) attention_mask.shape=torch.Size([1, 191]) labels.shape=torch.Size([1, 191])

loss=tensor(1.7721, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█▏        | 228/2000 [02:43<20:51,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[500, 436]] input_ids.shape=torch.Size([1, 197]) attention_mask.shape=torch.Size([1, 197]) labels.shape=torch.Size([1, 197])

loss=tensor(1.8571, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 11%|█▏        | 229/2000 [02:43<21:18,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 195]) attention_mask.shape=torch.Size([1, 195]) labels.shape=torch.Size([1, 195])

loss=tensor(1.9483, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 230/2000 [02:44<21:37,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 180]) attention_mask.shape=torch.Size([1, 180]) labels.shape=torch.Size([1, 180])

loss=tensor(1.8379, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 231/2000 [02:45<22:15,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 640]] input_ids.shape=torch.Size([1, 135]) attention_mask.shape=torch.Size([1, 135]) labels.shape=torch.Size([1, 135])

loss=tensor(1.9842, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 232/2000 [02:46<22:04,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 333]] input_ids.shape=torch.Size([1, 220]) attention_mask.shape=torch.Size([1, 220]) labels.shape=torch.Size([1, 220])

loss=tensor(2.2114, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 233/2000 [02:46<19:56,  1.48it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[375, 500]] input_ids.shape=torch.Size([1, 196]) attention_mask.shape=torch.Size([1, 196]) labels.shape=torch.Size([1, 196])

loss=tensor(1.9724, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 234/2000 [02:47<18:22,  1.60it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 482]] input_ids.shape=torch.Size([1, 208]) attention_mask.shape=torch.Size([1, 208]) labels.shape=torch.Size([1, 208])

loss=tensor(1.6774, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 235/2000 [02:48<19:33,  1.50it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 639]] input_ids.shape=torch.Size([1, 184]) attention_mask.shape=torch.Size([1, 184]) labels.shape=torch.Size([1, 184])

loss=tensor(2.0591, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 236/2000 [02:48<20:18,  1.45it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 180]) attention_mask.shape=torch.Size([1, 180]) labels.shape=torch.Size([1, 180])

loss=tensor(1.8710, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 237/2000 [02:49<20:50,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[375, 500]] input_ids.shape=torch.Size([1, 181]) attention_mask.shape=torch.Size([1, 181]) labels.shape=torch.Size([1, 181])

loss=tensor(2.1594, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 238/2000 [02:50<18:55,  1.55it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 166]) attention_mask.shape=torch.Size([1, 166]) labels.shape=torch.Size([1, 166])

loss=tensor(2.1762, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 239/2000 [02:50<19:47,  1.48it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 383]] input_ids.shape=torch.Size([1, 173]) attention_mask.shape=torch.Size([1, 173]) labels.shape=torch.Size([1, 173])

loss=tensor(2.0457, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 240/2000 [02:51<18:13,  1.61it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[425, 640]] input_ids.shape=torch.Size([1, 220]) attention_mask.shape=torch.Size([1, 220]) labels.shape=torch.Size([1, 220])

loss=tensor(2.0562, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 241/2000 [02:52<19:28,  1.51it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 208]) attention_mask.shape=torch.Size([1, 208]) labels.shape=torch.Size([1, 208])

loss=tensor(1.8840, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 242/2000 [02:52<20:18,  1.44it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 195]) attention_mask.shape=torch.Size([1, 195]) labels.shape=torch.Size([1, 195])

loss=tensor(2.2904, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 243/2000 [02:53<20:49,  1.41it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 428]] input_ids.shape=torch.Size([1, 177]) attention_mask.shape=torch.Size([1, 177]) labels.shape=torch.Size([1, 177])

loss=tensor(2.0149, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 244/2000 [02:54<21:05,  1.39it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 177]) attention_mask.shape=torch.Size([1, 177]) labels.shape=torch.Size([1, 177])

loss=tensor(2.0130, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 245/2000 [02:55<21:39,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[399, 640]] input_ids.shape=torch.Size([1, 168]) attention_mask.shape=torch.Size([1, 168]) labels.shape=torch.Size([1, 168])

loss=tensor(1.7951, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 246/2000 [02:55<21:40,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[430, 640]] input_ids.shape=torch.Size([1, 153]) attention_mask.shape=torch.Size([1, 153]) labels.shape=torch.Size([1, 153])

loss=tensor(2.0119, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 247/2000 [02:56<21:35,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 163]) attention_mask.shape=torch.Size([1, 163]) labels.shape=torch.Size([1, 163])

loss=tensor(1.7096, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 248/2000 [02:57<21:42,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 205]) attention_mask.shape=torch.Size([1, 205]) labels.shape=torch.Size([1, 205])

loss=tensor(1.9660, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▏        | 249/2000 [02:58<21:51,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 220]) attention_mask.shape=torch.Size([1, 220]) labels.shape=torch.Size([1, 220])

loss=tensor(1.9802, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 12%|█▎        | 250/2000 [02:58<22:00,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 425]] input_ids.shape=torch.Size([1, 219]) attention_mask.shape=torch.Size([1, 219]) labels.shape=torch.Size([1, 219])

loss=tensor(1.8174, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 251/2000 [02:59<22:08,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 203]) attention_mask.shape=torch.Size([1, 203]) labels.shape=torch.Size([1, 203])

loss=tensor(1.7702, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 252/2000 [03:00<22:09,  1.31it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 185]) attention_mask.shape=torch.Size([1, 185]) labels.shape=torch.Size([1, 185])

loss=tensor(1.8588, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 253/2000 [03:01<22:02,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 200]) attention_mask.shape=torch.Size([1, 200]) labels.shape=torch.Size([1, 200])

loss=tensor(1.7142, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 254/2000 [03:01<22:00,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 489]] input_ids.shape=torch.Size([1, 166]) attention_mask.shape=torch.Size([1, 166]) labels.shape=torch.Size([1, 166])

loss=tensor(1.9930, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 255/2000 [03:02<21:53,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 428]] input_ids.shape=torch.Size([1, 145]) attention_mask.shape=torch.Size([1, 145]) labels.shape=torch.Size([1, 145])

loss=tensor(1.8705, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 256/2000 [03:03<21:41,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 218]) attention_mask.shape=torch.Size([1, 218]) labels.shape=torch.Size([1, 218])

loss=tensor(1.6935, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 257/2000 [03:04<21:50,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 194]) attention_mask.shape=torch.Size([1, 194]) labels.shape=torch.Size([1, 194])

loss=tensor(1.9781, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 258/2000 [03:04<21:48,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 199]) attention_mask.shape=torch.Size([1, 199]) labels.shape=torch.Size([1, 199])

loss=tensor(2.0350, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 259/2000 [03:05<21:50,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 428]] input_ids.shape=torch.Size([1, 197]) attention_mask.shape=torch.Size([1, 197]) labels.shape=torch.Size([1, 197])

loss=tensor(1.7844, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 260/2000 [03:06<22:16,  1.30it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 543]] input_ids.shape=torch.Size([1, 198]) attention_mask.shape=torch.Size([1, 198]) labels.shape=torch.Size([1, 198])

loss=tensor(1.9036, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 261/2000 [03:07<22:07,  1.31it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[500, 375]] input_ids.shape=torch.Size([1, 166]) attention_mask.shape=torch.Size([1, 166]) labels.shape=torch.Size([1, 166])

loss=tensor(2.0869, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 262/2000 [03:07<19:44,  1.47it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 168]) attention_mask.shape=torch.Size([1, 168]) labels.shape=torch.Size([1, 168])

loss=tensor(2.0960, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 263/2000 [03:08<20:21,  1.42it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[426, 640]] input_ids.shape=torch.Size([1, 146]) attention_mask.shape=torch.Size([1, 146]) labels.shape=torch.Size([1, 146])

loss=tensor(2.1304, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 264/2000 [03:09<20:44,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 231]) attention_mask.shape=torch.Size([1, 231]) labels.shape=torch.Size([1, 231])

loss=tensor(2.0529, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 265/2000 [03:09<21:16,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 200]) attention_mask.shape=torch.Size([1, 200]) labels.shape=torch.Size([1, 200])

loss=tensor(2.1891, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 266/2000 [03:10<21:27,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 196]) attention_mask.shape=torch.Size([1, 196]) labels.shape=torch.Size([1, 196])

loss=tensor(2.0729, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 267/2000 [03:11<21:31,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[640, 361]] input_ids.shape=torch.Size([1, 197]) attention_mask.shape=torch.Size([1, 197]) labels.shape=torch.Size([1, 197])

loss=tensor(1.9952, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 268/2000 [03:11<19:25,  1.49it/s]Forward Call
images.shape=torch.Size([1, 1, 3, 3, 384, 384]) image_size=[[342, 640]] input_ids.shape=torch.Size([1, 184]) attention_mask.shape=torch.Size([1, 184]) labels.shape=torch.Size([1, 184])

loss=tensor(2.0866, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 13%|█▎        | 269/2000 [03:12<17:52,  1.61it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 177]) attention_mask.shape=torch.Size([1, 177]) labels.shape=torch.Size([1, 177])

loss=tensor(1.8912, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▎        | 270/2000 [03:13<18:56,  1.52it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 173]) attention_mask.shape=torch.Size([1, 173]) labels.shape=torch.Size([1, 173])

loss=tensor(2.0176, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▎        | 271/2000 [03:13<19:45,  1.46it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 145]) attention_mask.shape=torch.Size([1, 145]) labels.shape=torch.Size([1, 145])

loss=tensor(1.8716, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▎        | 272/2000 [03:14<20:09,  1.43it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 426]] input_ids.shape=torch.Size([1, 198]) attention_mask.shape=torch.Size([1, 198]) labels.shape=torch.Size([1, 198])

loss=tensor(2.0148, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▎        | 273/2000 [03:15<20:36,  1.40it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 216]) attention_mask.shape=torch.Size([1, 216]) labels.shape=torch.Size([1, 216])

loss=tensor(1.6737, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▎        | 274/2000 [03:16<21:00,  1.37it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 457]] input_ids.shape=torch.Size([1, 194]) attention_mask.shape=torch.Size([1, 194]) labels.shape=torch.Size([1, 194])

loss=tensor(2.0784, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 275/2000 [03:16<21:09,  1.36it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 199]) attention_mask.shape=torch.Size([1, 199]) labels.shape=torch.Size([1, 199])

loss=tensor(1.6755, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 276/2000 [03:17<21:46,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 189]) attention_mask.shape=torch.Size([1, 189]) labels.shape=torch.Size([1, 189])

loss=tensor(2.1767, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 277/2000 [03:18<21:45,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 424]] input_ids.shape=torch.Size([1, 181]) attention_mask.shape=torch.Size([1, 181]) labels.shape=torch.Size([1, 181])

loss=tensor(2.0406, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 278/2000 [03:19<21:43,  1.32it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 169]) attention_mask.shape=torch.Size([1, 169]) labels.shape=torch.Size([1, 169])

loss=tensor(1.7646, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 279/2000 [03:20<21:35,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 143]) attention_mask.shape=torch.Size([1, 143]) labels.shape=torch.Size([1, 143])

loss=tensor(1.9004, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 280/2000 [03:20<21:28,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[389, 500]] input_ids.shape=torch.Size([1, 222]) attention_mask.shape=torch.Size([1, 222]) labels.shape=torch.Size([1, 222])

loss=tensor(2.0606, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 281/2000 [03:21<21:34,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 193]) attention_mask.shape=torch.Size([1, 193]) labels.shape=torch.Size([1, 193])

loss=tensor(1.8147, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 282/2000 [03:22<21:30,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 427]] input_ids.shape=torch.Size([1, 186]) attention_mask.shape=torch.Size([1, 186]) labels.shape=torch.Size([1, 186])

loss=tensor(1.6823, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 283/2000 [03:23<21:30,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[403, 640]] input_ids.shape=torch.Size([1, 190]) attention_mask.shape=torch.Size([1, 190]) labels.shape=torch.Size([1, 190])

loss=tensor(1.7837, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 284/2000 [03:23<21:30,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 168]) attention_mask.shape=torch.Size([1, 168]) labels.shape=torch.Size([1, 168])

loss=tensor(2.0466, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 285/2000 [03:24<21:25,  1.33it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 162]) attention_mask.shape=torch.Size([1, 162]) labels.shape=torch.Size([1, 162])

loss=tensor(2.0596, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 286/2000 [03:25<21:20,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 480]] input_ids.shape=torch.Size([1, 154]) attention_mask.shape=torch.Size([1, 154]) labels.shape=torch.Size([1, 154])

loss=tensor(2.4323, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 287/2000 [03:25<21:14,  1.34it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[480, 640]] input_ids.shape=torch.Size([1, 142]) attention_mask.shape=torch.Size([1, 142]) labels.shape=torch.Size([1, 142])

loss=tensor(1.9592, device='cuda:0', grad_fn=<_DDPSinkBackward>)
 14%|█▍        | 288/2000 [03:26<21:10,  1.35it/s]Forward Call
images.shape=torch.Size([1, 1, 5, 3, 384, 384]) image_size=[[640, 528]] input_ids.shape=torch.Size([1, 202]) attention_mask.shape=torch.Size([1, 202]) labels.shape=torch.Size([1, 202])

